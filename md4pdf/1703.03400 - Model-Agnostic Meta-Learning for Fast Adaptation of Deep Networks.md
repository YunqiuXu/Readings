# 1703.03400 - Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks

+ **Yunqiu Xu**
+ Other reference:
    + https://www.jiqizhixin.com/articles/2017-07-20-4
    + http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/
    + https://github.com/cbfinn/maml

## 1. Introduction
+ The goal of meta-learning: train a model with some learning tasks, then it can solve new tasks with only a few samples
+ Our work: 
    + The initial parameters of the model are explicitly trained first 
    + Then this model can be generated to new task with a small number of training samples / gradient steps on that task

+ Do not use following meta-learning methods: 
    + Learn an update function or learning rules
    + Expand the number of learned parameters
    + Place constraints on the model architecture

+ Our advantage:
    + General and model-agnostic: can be directly applied to any learning problem and model with a few samples / GD steps
    + Can easily handle different architectures / problem settings / loss functins with minimal modification
    + Easy and fast to fine-tune

## 2. MAML
### 2.1 Meta-Learning Problem Set-Up
+ Goal: Treat entire tasks as training examples, then train a model with these learning tasks, thus it can solve new tasks with only a few samples / steps
+ Model $f: x \rightarrow a$
    + $x$ : observations
    + $a$ : outputs
    + During meta-learning, the model is trained to be able to adapt to a large or infinite number of tasks.
+ $p(T)$ is a distribution over tasks, each task $T = \{L(x_1,a_1,...,x_H,a_H), q(x_1), q(x_{t+1}|x_t,a_t),H\}$ :
    + $L \rightarrow R$ : loss function
    + $q(x_1)$ : distribution over initial observations
    + $q(x_{t+1}|x_t,a_t)$ : transiion distribution
    + $H$ : episode length, model may generate samples of length H by choosing an output $a_t$ at each time $t$

+ K-shot meta-learning:
    + Sample a new task $T_i$ from $p(T)$
    + Train model with K samples from $q_i$
    + Generate feedback $L_{T_i}$ from $T_i$
    + Test on new samples from $T_i$
    + Treat the test error on sampled tasks $T_i$ as the training error of meta-learning process
    + At the end of meta-learning, sample new tasks from $p(T)$
    + Meta-perfomance: model $f$ 's performance after learning from K samples

### 2.2. A MAML Algorithm
+ How to encourage the emergence of general-purpose representations:
    + Learn a model that gradient-based learning rule can make rapid progress on new tasks drawn from $p(T)$ without overfitting
    + Find model parameters that are sensitive to changes of the task $\rightarrow$ small changes lead to large improvement

+ Model $f_{\theta}$
    + No assumption on the form of model
    + Only assume that the model is parameterized by params $\theta$, the loss function can be optimized by gradient through these params
    + When adapting to a new task $T_i$, $\theta$ becomes $\theta_i'$ by gradient updateing
    $$\theta_i' = \theta - \alpha \nabla_{\theta}L_{T_i}(f_{\theta})$$
    + Step size $\alpha$ : fixed as a hyperparameter or meta-learned.
    ![2017-11-27 16-00-06屏幕截图.png-48.9kB][1]

+ Meta-objective:
$$ min_{\theta} \sum_{T_i \sim p(T)} L_{T_i}(f_{\theta_i'}) = \sum_{T_i \sim p(T)}L_{T_i}(f_{\theta - \alpha \nabla_{\theta}L_{T_i}(f_{\theta})})$$

+ Meta-optimization across tasks:
    + Performed over params $\theta$
    + The objective is computed using updated params $\theta'$
    + Update $\theta$ using SGD, $\beta$ is meta stepsize
    $$\theta \leftarrow \theta - \beta \nabla_{\theta} \sum_{T_i \sim p(T)} L_{T_i}(f_{\theta_i'})$$

+ Entire algorithm
![2017-11-27 16-22-00屏幕截图.png-93.8kB][2]

### 2.3 Species of MAML
+ Two kinds of MAML are shown below, the only difference is loss function
+ MAML for few-shot supervised learning: MSE or cross validation
+ MAML for RL: reward function, as we need to maximize reward, in loss function we multiply "-1" to minimize the value

$$L_{T_i}(f_{\psi}) = -E_{x_t,a_t \sim f_{\psi, q_{T_i}}} \left[  \sum_{t=1}^HR_i(x_t,a_t)\right] \text{   (4)}$$

![2017-11-27 21-05-32屏幕截图.png-95.6kB][3]

## 4. Related Work of Meta-Learning

![2017-11-27 21-28-20屏幕截图.png-173kB][4]

+ RNNs as learners: MANN
    + Search space includes all conceivable ML algorithms
    + Moves the burden of innovation to RNNs
    + Ignors advances achieved in ML by humans
    + The results are not good

+ Metric learning: Siamese nets, matching nets
    + Learn a metric in input space
    + Specialized to one/few-shot classification
    + Can't use in other problems

+ Optimizer learning: meta-learner LSTM
    + Learn parameter update given gradients (search space includes SGD, RMSProp, Adam etc)
    + Applicable to any architecture / task
    + But we can achieve better performance with MAML


## 5. Experimental Evaluation
+ Questions need to be answered:
    + Can MAML enable fast learning of new tasks
    + Can MAML be used for meta-learning in multiple different domains
    + Can a model learned with MAML continue to improve with additional gradient updates and/or examples

+ Classification result: see 4
+ RL result:

![2017-11-27 21-40-07屏幕截图.png-111.3kB][5]
![2017-11-27 21-40-17屏幕截图.png-166.1kB][6]
    

## 6. Discussion and Future Work
+ Benefits:
    + Simple, does not introduce any learned parameters for meta-learning
    + Any gradient-based model representation / differentiable objective
    + Adaptation on new tasks
+ Future work:
    + Generalize meta-learning technique to apply to any problem and any model
    + Make multitask initialization a standard ingredient in DL and RL
        


  [1]: http://static.zybuluo.com/VenturerXu/qwywwlsg9fbaf3p2vnd9mve9/2017-11-27%2016-00-06%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [2]: http://static.zybuluo.com/VenturerXu/f4ghc4fgaljmr6p5xosob9y1/2017-11-27%2016-22-00%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [3]: http://static.zybuluo.com/VenturerXu/lulbsmhte8ncq6fdyc9lcm9d/2017-11-27%2021-05-32%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [4]: http://static.zybuluo.com/VenturerXu/xgmwsr30ngef64hc873qhi47/2017-11-27%2021-28-20%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [5]: http://static.zybuluo.com/VenturerXu/5wqw8d7cbna3rqoydretifs2/2017-11-27%2021-40-07%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [6]: http://static.zybuluo.com/VenturerXu/kzve88ps3f5ijvjctm8zxt7d/2017-11-27%2021-40-17%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png