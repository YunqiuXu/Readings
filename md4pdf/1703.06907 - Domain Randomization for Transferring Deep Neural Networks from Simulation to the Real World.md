# 1703.06907 - Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World

+ **Yunqiu Xu**

+ Brief review:
    + Work about "Sim-to-real transfer"
    + Train on similated images and then transfer to real images by randomizing rendering in the simulator
    + Domain randomization: colors, textures, lighting conditions, and camera settings in simulated scenes
    + To some extent this is more like robot controling, and the example is about object localization and grasping

+ Other reference and further work:
    + [OPENAI - Spam Detection in the Physical World][1]
    + [OPENAI - Robots that Learn][2] : [One-Shot Imitation Learning][3]
    + [OPENAI - Generalizing from Simulation][4]
        + [Dynamics Randomization][5]
        + [Image-Based Learning][6]
    
-----

## 1. Introduction
+ Why learning in simulation:
    + DRL employs random exploration, which can be dangerous on physical hardware
    + It's impractical to collect millions of real-world samples

+ Similar to "imitation learning" and "transfer learning", we can learn policies for complex behaviors in simulation, then transfer policies to adapt real environment

+ Challenges: reality gap
    + System identification is time-consuming and error-prone
    + Unmodeled physical effects of real world
    + Low-fidelity simulated sensors are insufficient

## 2. Method
+ Goal: Given some objects of interest $\{s_i\}_i$ , train an object detector $d(I_0)$ that maps a single monocular camera
frame $I_0$ to the Cartesian coordinates $\{(x_i , y_i , z_i )\}_i$ of each object
+ Approach: train a deep neural network in simulation using domain randomization

+ Domain randomization: 
    + Goal: provide enough simulated variability at training time such that at test time the model is able to generalize to real-world data
    + If the variability in simulation is significant enough, models trained in simulation will generalize to the real world with no additional training
    + In this work, we only focus on the task of training a neural network to detect the location of an object

+ The architecture of model is like VGG-16:
![2017-11-30 21-20-44屏幕截图.png-140kB][7]

## 3. Experiment
+ Localization accuracy of detectors in real world:
    ![2017-11-30 21-33-58屏幕截图.png-49.7kB][8]
    + Localize objects to within 1.5cm (on average) in the real world
    + Perform well in the presence of clutter and partial occlusions
    + Still over-fitting the simulated training data, but comparable with traditional technique on higher-resolution images

+ Ablation study, assess the sensitivity of some elements
    ![2017-11-30 21-34-33屏幕截图.png-39kB][9]
    + Incorporating distractors during training: critical
    + Randomizing the position of the camera: not critical
    + Adding noise: not critical but helpful to avoid local optima


  [1]: https://blog.openai.com/spam-detection-in-the-physical-world/
  [2]: https://blog.openai.com/robots-that-learn/
  [3]: https://arxiv.org/abs/1703.07326
  [4]: https://blog.openai.com/generalizing-from-simulation/
  [5]: https://arxiv.org/abs/1710.06537
  [6]: https://arxiv.org/abs/1710.06542
  [7]: http://static.zybuluo.com/VenturerXu/ho9gu7prv9hefclj30bronqi/2017-11-30%2021-20-44%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [8]: http://static.zybuluo.com/VenturerXu/4t9tmn0gen4yusiejebf2bbr/2017-11-30%2021-33-58%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [9]: http://static.zybuluo.com/VenturerXu/m4aazgldbiwuiysfry2v7ymc/2017-11-30%2021-34-33%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png