# 1709.04905 - One-Shot Visual Imitation Learning via Meta-Learning

+ **Yunqiu Xu**
+ Other reference:
    + Presentation: https://www.youtube.com/watch?v=_9Ny2ghjwuY
    + Code: https://github.com/tianheyu927/mil

---

## 1. Introduction
+ Challenge: learning each skill from a scratch is infeasible
+ One-Shot Visual Imitation Learning via Meta-Learning
    + Reuse past experience and learn new skills from a single
demonstration
    + Visual: use raw visual inputs
    + Meta-Learning: MAML [C. Finn et.al. 2017](https://arxiv.org/abs/1703.03400)
+ Do not take task identity / demonstration as the input into a contextual policy: learn parameterized policy, adapt into new tasks through gradient updates


## 2. Related work
+ In this work, the state of env is unknown $\rightarrow$ should be learned from raw sensory inputs
+ Two challenges for learning from demonstrations:
    + Compounding errors: not in this work
    + **The need of a large number of demonstrations for each task**
+ Inverse RL can reduce the number of demonstrations, but requires additional robot experience to optimize the reward  [C. Finn et.al. 2016](https://arxiv.org/abs/1603.00448)
+ How we tackle this: share data across tasks
    + First, use a dataset of demonstrations of many other tasks for meta learning, then we can learn a new task from its single demonstration
    + Some existed work:
        + Contextual policies: provide the task as an input to the policy or value function
        + Train a variety of controllers, then learn a mapping from given task to controller parameters
    + What we use: **meta-learning**


## 3. Meta-Imitation Learning

![2017-11-27 00-18-58屏幕截图.png-58.3kB][1]

+ By training for adaptation across tasks, meta-learning effectively treats entire tasks as datapoints.
+ MAML
![2017-11-27 00-11-57屏幕截图.png-470.7kB][2]

+ Extend MAML to MIL
![2017-11-27 00-13-27屏幕截图.png-621.6kB][3]

+ Loss function (Equation 2 in pseudo code)
![2017-11-27 00-21-51屏幕截图.png-9.2kB][4]

+ Network architecture
![2017-11-27 00-25-32屏幕截图.png-202.3kB][5]

+ Training and testing
![MIL.png-303.9kB][6]

## 4. Experiment

![2017-11-27 00-28-50屏幕截图.png-84.8kB][7]
![2017-11-27 00-29-05屏幕截图.png-367.4kB][8]
![2017-11-27 00-29-25屏幕截图.png-516.5kB][9]
![2017-11-27 00-29-45屏幕截图.png-795.9kB][10]

+ Demo: let robot put the ball in blue cup
+ Test: shuffle the cups and let robot achieve the goal

## 5. Summary and Ongoing Work (On CoRL)
+ Summary:
    + reuse prior experience when learning in new settings
    + learning-to-learn enables effective one-shot learning
+ Ongoing work: one-shot imitation from human video $\rightarrow$ during demo, let human put the ball in cup 




  [1]: http://static.zybuluo.com/VenturerXu/ocreknyauidkwv2z67xrx9t3/2017-11-27%2000-18-58%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [2]: http://static.zybuluo.com/VenturerXu/xk2uv5qbh24jqhpuhhfou2bo/2017-11-27%2000-11-57%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [3]: http://static.zybuluo.com/VenturerXu/8pfisiluxzgl3rxps5voiofl/2017-11-27%2000-13-27%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [4]: http://static.zybuluo.com/VenturerXu/b52p7s9ze6n9isgqkssofbox/2017-11-27%2000-21-51%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [5]: http://static.zybuluo.com/VenturerXu/wneggi8ilau5hmj4qb3rhjhx/2017-11-27%2000-25-32%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [6]: http://static.zybuluo.com/VenturerXu/dor4y3okiksugzirzannd405/MIL.png
  [7]: http://static.zybuluo.com/VenturerXu/un1gpjtiu95kcvyhwnaz6l54/2017-11-27%2000-28-50%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [8]: http://static.zybuluo.com/VenturerXu/2jy7768xn9md5ppkepvttzmn/2017-11-27%2000-29-05%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [9]: http://static.zybuluo.com/VenturerXu/6nh1t40henug7hatntbfflk0/2017-11-27%2000-29-25%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [10]: http://static.zybuluo.com/VenturerXu/dg1cd6tnkxfab1ptz8ie10rr/2017-11-27%2000-29-45%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png