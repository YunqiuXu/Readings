# 1711.10314 - Crossmodal Attentive Skill Learner

+ **Yunqiu Xu**
+ NIPS 2017 HRL Workshop
+ Related reading:
    + A2OC, a prior work : [Harb et al, 2017. When waiting is not an option: Learning options with a deliberation cost][1]
    + Source code : https://github.com/shayegano/CASL

---

## 1. Introduction

+ Challenges: similar to other HRL, this paper tries to solve
    + Durative tasks (long term)
    + Sparse reward

+ Related insights:
    + Temporal abstraction: enables exploitation of domain regularities to form sub-goals (options)
    + Options (sub-goals) : 
        + Improve learning by mitigating scalability issues in long-duration missions 
        + Reduce effective number of decision epochs
    + Attention:
        + Focus on the most related parts
        + Capture longer-term correlations in its encoded state

+ Our aim: learn rich skills that attend to and exploit multi-sensor signals at given moments
        
+ Our work: CASL
    + Based on **option framework** and **A2OC** 
    + Crossmodal : use multi-sensor (audio and video)
    + Attention: anticipate and identify usefule latent features, filter irrelevant sensor modalities

## 2. Background
+ I omit the part of POMDP and focus on "Options"
+ Option framework: Sutton et al, 1999
+ Similar to previous reading, here "option" is "sub-task"
+ An option $\omega \in \Omega$ consists of:
    + Initiation set $I \subseteq S$
    + Intra-option policy $\pi_{\omega} : S \rightarrow A$ , this is **sub-policy**
    + Termination condition $\beta_{\omega} : S \rightarrow [0,1]$
+ Given a state, master policy $\pi$ select an option (suitable initiation set), then its intra-option policy will be executed to reach terminate state of this subtask $\rightarrow$ a new state for next iteration until final end

+ **A2OC**: prior work, extend A3C to Option-Critic
    + $Q_{\Omega}(s,\omega)$ : Option value function for option $\omega \in \Omega$
$$Q_{\Omega}(s,\omega) = \sum_{a} \pi_{\omega}(a|s)\left((r(s,a) + \gamma \sum_{s'} T(s'|s,a)U(s',\omega)\right)$$
    + $U(s', \omega)$ : option utality function
$$U(s',\omega) = (1-\beta_{\omega}(s')) Q_{\Omega}(\omega, s') + \beta_{\omega}(s')(V_{\Omega}(s') - c)$$
        + If $\beta_{\omega}(s') = 1$, sub-task ends $\rightarrow$ $U(s',\omega) = V_{\Omega}(s') - c$ $\rightarrow$ Master policy
        + If $\beta_{\omega}(s') = 0$, still sub-task $\rightarrow$ $U(s',\omega) = Q_{\Omega}(\omega, s')$
    + $c$ : deliberation cost, add penalty when options terminate $\rightarrow$ **let options terminate less frequently**
    + $V_{\Omega}(s')$ : value function over options (master policy $\pi_{Omega}$ )
$$V_{\Omega}(s') = \sum_{\omega}\pi_{\Omega}(\omega|s')Q_{\Omega}(\omega,s')$$

## 3. Approach
### 3.1 Attentive Mechanisms
+ Why we still need crossmodal attention?
    + Using crossmodal attention, agents combine internal beliefs with external stimuli
    + More effectively exploit multiple modes of input features for learning
    + Capture temporal crossmodal dependencies $\rightarrow$ faster and more proficient learning

### 3.2 Crossmodal Attentive Skill Learner

![2017-12-30 22-47-43屏幕截图.png-177.7kB][2]

+ $M$ : the number of sensors
    + There are 2 sensors in this graph
    + Sensor 1 is image, sensor 2 is audio
+ $x_1^t$ : features extracted by CNN from sensor 1 at time t
+ $\alpha_1^t$ : the relative importance for information from sensor 1 at time t

![2017-12-30 22-56-06屏幕截图.png-54.6kB][3]

+ Eq (4):
    + Exogeneous attention: over sensory features $x_m^t$
    + Endogeneous attention: over LSTM hidden state h^{t-1}
+ Eq (5):
    + Entropy regularization of attention outputs
    + Encourage exploration of crossmodal attention behaviors during training
    + **此处存疑: 这个 $\alpha$ 和之前的 "relative importance" 是一个东西么**

+ Eq (6):
    + Combine attended features $\alpha_m^tx_m^t$
    + Combine method: summed attention or concatenated attentation
    + Then we can feed $x_{+}^t$ to LSTM 

![2017-12-30 22-56-15屏幕截图.png-28.9kB][4]

+ LSTM captures temporal dependencies to estimate:
    + Option values: Eq (7)
    + Intra-option policies: Eq (8)
    + Termination conditions: Eq (9)

## 4. Experiment
+ Learning tasks with inherent reward sparsity and transition noise
    + Door puzzle domain
    + 2D-Minecraft domain
    + Arcade Learning Environment
+ Evaluation:
    + Performance of CASL : learning rate and transfer learning
    + Understand relationships between attention and memory mechanisms
    + Crossmodal learning: modify ALE to support audio queries

### 4.1 Performance of CASL
+ Attention improves LR, accelerates transfer
![2017-12-30 23-13-22屏幕截图.png-92.9kB][5]

+ Attention Necessary to Learn in Some Domains
![2017-12-30 23-19-40屏幕截图.png-82.4kB][6]

### 4.2 Interactions of Attention and Memory
![2017-12-31 01-20-07屏幕截图.png-199.7kB][7]

+ Fig (4.a) : Before t = 6, the audio signal is nearly "non-useful" $\rightarrow$ we need to check whether it's necessary to pay attention on it
+ Fig (4.b) and Fig (4.c) : Overall activations for forget and input LSTM gates
+ Result:
    + Before t = 6, the contribution of audio is zero (b/c), despite the attention in a is positive
    + When t = 6, forget gate drops and input gate increases $\rightarrow$ overwriting of previous memory states with new information
    + Thus attended audio input is the key contributor
    + After t = 6, move attention back to video $\rightarrow$ **listen to audio, but choose not to embed it into memory until the appropriate moment**

### 4.3 ALE

![2017-12-31 01-29-57屏幕截图.png-106.1kB][8]
![2017-12-31 01-32-31屏幕截图.png-59.6kB][9]

## 5. Summary
+ CASL:
    + Integrate A2OC
    + HRL + multiple sensory inputs (video + audio)
+ Feedback:
    + Interesting work, similar to human, we can make the agent to learn via both video and audio input
    + I need to check source code and prior work (A2OC) for more details

    
        
            


  [1]: https://arxiv.org/abs/1709.04571
  [2]: http://static.zybuluo.com/VenturerXu/iv08i4wyz7zckmtl1o2z5r7q/2017-12-30%2022-47-43%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [3]: http://static.zybuluo.com/VenturerXu/ytoraf3dl6f6s4d4tr47oinj/2017-12-30%2022-56-06%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [4]: http://static.zybuluo.com/VenturerXu/m6la6zplg7v6drwyv43u78k4/2017-12-30%2022-56-15%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [5]: http://static.zybuluo.com/VenturerXu/bzusets0t5azmhrzqd0kg0pm/2017-12-30%2023-13-22%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [6]: http://static.zybuluo.com/VenturerXu/1sa982ow8op3dlxe6yu8oaco/2017-12-30%2023-19-40%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [7]: http://static.zybuluo.com/VenturerXu/xo3sgdc6ntyttb7kawcyq1s8/2017-12-31%2001-20-07%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [8]: http://static.zybuluo.com/VenturerXu/c2a0qkorhqaiwdh2rffzzkg3/2017-12-31%2001-29-57%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png
  [9]: http://static.zybuluo.com/VenturerXu/ftjkf3ct5zelgiga30bhglby/2017-12-31%2001-32-31%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png